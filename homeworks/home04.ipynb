{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вебинар 4. Домашнее задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "        \n",
    "from metrics import precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Перенесите метрики в модуль metrics.py (убедится что они там)\n",
    "2. Перенесите функцию prefilter_items в модуль utils.py\n",
    "3. Создайте модуль recommenders.py. Напищите код для класса ниже \n",
    "(задание обсуждали на вебинаре, для первой функции практически сделали) и положите его в recommenders.py\n",
    "4. Проверьте, что все модули корректно импортируются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import ItemItemRecommender  # нужен для одного трюка\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "\n",
    "class MainRecommender:\n",
    "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    user_item_matrix: pd.DataFrame\n",
    "        Матрица взаимодействий user-item\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, weighting=True):\n",
    "        \n",
    "        self.user_top_items = data.groupby('user_id').apply(lambda x: \n",
    "                                                            [k for k, v in sorted([(row, qt) for row, qt in zip(x['item_id'], x['quantity']) if row != 999999], \n",
    "                                                                                  key=lambda y: y[1], \n",
    "                                                                                  reverse=True)])\n",
    "        \n",
    "        self.user_item_matrix = self.prepare_matrix(data)  # pd.DataFrame\n",
    "        self.id_to_itemid, self.id_to_userid, self.itemid_to_id, self.userid_to_id = self.prepare_dicts(self.user_item_matrix)\n",
    "        \n",
    "        if weighting:\n",
    "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T \n",
    "        \n",
    "        self.model = self.fit(self.user_item_matrix)\n",
    "        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n",
    "     \n",
    "    @staticmethod\n",
    "    def prepare_matrix(data, values='quantity', aggfunc='count'):\n",
    "        user_item_matrix = pd.pivot_table(data, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values=values, \n",
    "                                  aggfunc=aggfunc, \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "        user_item_matrix = user_item_matrix.astype(float) #\n",
    "        \n",
    "        return user_item_matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_dicts(user_item_matrix):\n",
    "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
    "        \n",
    "        userids = user_item_matrix.index.values\n",
    "        itemids = user_item_matrix.columns.values\n",
    "\n",
    "        matrix_userids = np.arange(len(userids))\n",
    "        matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "        id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "        userid_to_id = dict(zip(userids, matrix_userids))\n",
    "        \n",
    "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
    "     \n",
    "    @staticmethod\n",
    "    def fit_own_recommender(user_item_matrix):\n",
    "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
    "    \n",
    "        own_recommender = ItemItemRecommender(K=1, num_threads=4)\n",
    "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        \n",
    "        return own_recommender\n",
    "    \n",
    "    @staticmethod\n",
    "    def fit(user_item_matrix, n_factors=20, regularization=0.001, iterations=15, num_threads=4):\n",
    "        \"\"\"Обучает ALS\"\"\"\n",
    "        \n",
    "        model = AlternatingLeastSquares(factors=n_factors, \n",
    "                                        regularization=regularization,\n",
    "                                        iterations=iterations,  \n",
    "                                        num_threads=num_threads)\n",
    "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def get_similar_items_recommendation(self, user, N=5):\n",
    "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
    "        top_items = self.user_top_items[user]\n",
    "        recs_for_items = []\n",
    "        for item in top_items[:N]:\n",
    "            recs_for_items.append([self.id_to_itemid[self.model.similar_items(self.itemid_to_id[item], N=N + 1)[i][0]] for i in range(1, N + 1)])\n",
    "        \n",
    "        # Стараемся добиться максимально релевантных, неповторяющихся рекомендаций\n",
    "        rec_list = []\n",
    "        for i in range(1, N+1):\n",
    "            for recs in recs_for_items:\n",
    "                for rec in recs[:i]:\n",
    "                    if rec not in rec_list:\n",
    "                        rec_list.append(rec)\n",
    "            if len(rec_list) >= N:\n",
    "                rec_list = rec_list[:N]\n",
    "                break\n",
    "\n",
    "        assert len(rec_list) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return rec_list\n",
    "    \n",
    "    def get_similar_users_recommendation(self, user, N=5):\n",
    "        \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
    "    \n",
    "        res = self.own_recommender.recommend(userid=self.userid_to_id[user], \n",
    "                        user_items=csr_matrix(self.user_item_matrix).tocsr(), \n",
    "                        N=N, \n",
    "                        filter_already_liked_items=False, \n",
    "                        filter_items=None, \n",
    "                        recalculate_user=False)\n",
    "\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что все работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n0     2375  26984851472    1  1004906         1         1.39       364   \n1     2375  26984851472    1  1033142         1         0.82       364   \n\n   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n0         -0.6        1631        1          0.0                0.0  \n1          0.0        1631        1          0.0                0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>basket_id</th>\n      <th>day</th>\n      <th>item_id</th>\n      <th>quantity</th>\n      <th>sales_value</th>\n      <th>store_id</th>\n      <th>retail_disc</th>\n      <th>trans_time</th>\n      <th>week_no</th>\n      <th>coupon_disc</th>\n      <th>coupon_match_disc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2375</td>\n      <td>26984851472</td>\n      <td>1</td>\n      <td>1004906</td>\n      <td>1</td>\n      <td>1.39</td>\n      <td>364</td>\n      <td>-0.6</td>\n      <td>1631</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2375</td>\n      <td>26984851472</td>\n      <td>1</td>\n      <td>1033142</td>\n      <td>1</td>\n      <td>0.82</td>\n      <td>364</td>\n      <td>0.0</td>\n      <td>1631</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/retail_train.csv')\n",
    "\n",
    "data.columns = [col.lower() for col in data.columns]\n",
    "data.rename(columns={'household_key': 'user_id',\n",
    "                    'product_id': 'item_id'},\n",
    "           inplace=True)\n",
    "\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   item_id  manufacturer    department     brand            commodity_desc  \\\n0    25671             2       GROCERY  National                  FRZN ICE   \n1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n\n            sub_commodity_desc curr_size_of_product  \n0          ICE - CRUSHED/CUBED                22 LB  \n1  NO SUBCOMMODITY DESCRIPTION                       ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>manufacturer</th>\n      <th>department</th>\n      <th>brand</th>\n      <th>commodity_desc</th>\n      <th>sub_commodity_desc</th>\n      <th>curr_size_of_product</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25671</td>\n      <td>2</td>\n      <td>GROCERY</td>\n      <td>National</td>\n      <td>FRZN ICE</td>\n      <td>ICE - CRUSHED/CUBED</td>\n      <td>22 LB</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26081</td>\n      <td>2</td>\n      <td>MISC. TRANS.</td>\n      <td>National</td>\n      <td>NO COMMODITY DESCRIPTION</td>\n      <td>NO SUBCOMMODITY DESCRIPTION</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features = pd.read_csv('../data/product.csv')\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "\n",
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coraleks/Projects/GeekBrainsAI/RecSys/homeworks/utils.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['price'] = self.data['sales_value'] / (np.maximum(self.data['quantity'], 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 86865 to 5001\n"
     ]
    }
   ],
   "source": [
    "from utils import FilterLower, FilterMax, FilterNonDepartment, TopBayer, PrefilterSeq, LowestPopularity, OverPopular, LongTimeNoSold\n",
    "n_items_before = data_train['item_id'].nunique()\n",
    "\n",
    "process_list=[FilterLower(low=1), FilterMax(max=60), FilterNonDepartment(item_features), OverPopular(popularity=0.5), LowestPopularity(popularity=0.01), LongTimeNoSold(weeks=62),\n",
    "              TopBayer(take_n_popular=5000)]\n",
    "\n",
    "filter = PrefilterSeq(data_train, process_list)\n",
    "data_train=filter.processing()\n",
    "\n",
    "n_items_after = data_train['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                                             actual\n0        1  [821867, 834484, 856942, 865456, 889248, 90795...\n1        3  [835476, 851057, 872021, 878302, 879948, 90963...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>actual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[821867, 834484, 856942, 865456, 889248, 90795...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>[835476, 851057, 872021, 878302, 879948, 90963...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = data_test.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result.columns=['user_id', 'actual']\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee930726e2bf4253b2d14600af346199"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2479 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "521629312fcc47eaac856aa7e9fd5056"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 4194 is out of bounds for axis 0 with size 2479",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m popularity \u001B[38;5;241m=\u001B[39m popularity\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m      8\u001B[0m popularity\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquantity\u001B[39m\u001B[38;5;124m'\u001B[39m], ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 10\u001B[0m popularity[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilar_recommendation_bpr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mpopularity\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muser_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecomender\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_similar_items_recommendation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/GeekBrainsAI/RecSys/venv/lib/python3.8/site-packages/pandas/core/series.py:4433\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4324\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4325\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4328\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4329\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4330\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4331\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4332\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4431\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/GeekBrainsAI/RecSys/venv/lib/python3.8/site-packages/pandas/core/apply.py:1082\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m   1079\u001B[0m     \u001B[38;5;66;03m# if we are a string, try to dispatch\u001B[39;00m\n\u001B[1;32m   1080\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m-> 1082\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/GeekBrainsAI/RecSys/venv/lib/python3.8/site-packages/pandas/core/apply.py:1137\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1131\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m   1132\u001B[0m         \u001B[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001B[39;00m\n\u001B[1;32m   1133\u001B[0m         \u001B[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001B[39;00m\n\u001B[1;32m   1134\u001B[0m         \u001B[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m         \u001B[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[39;00m\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;66;03m# \"Callable[[Any], Any]\"\u001B[39;00m\n\u001B[0;32m-> 1137\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1140\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1144\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1145\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32mpandas/_libs/lib.pyx:2870\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      7\u001B[0m popularity \u001B[38;5;241m=\u001B[39m popularity\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m      8\u001B[0m popularity\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquantity\u001B[39m\u001B[38;5;124m'\u001B[39m], ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 10\u001B[0m popularity[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilar_recommendation_bpr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m popularity[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mrecomender\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_similar_items_recommendation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36mMainRecommender.get_similar_items_recommendation\u001B[0;34m(self, user, N)\u001B[0m\n\u001B[1;32m     92\u001B[0m recs_for_items \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m top_items[:N]:\n\u001B[0;32m---> 94\u001B[0m     recs_for_items\u001B[38;5;241m.\u001B[39mappend([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid_to_itemid[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39msimilar_items(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitemid_to_id[item], N\u001B[38;5;241m=\u001B[39mN \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)[i][\u001B[38;5;241m0\u001B[39m]] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, N \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)])\n\u001B[1;32m     96\u001B[0m \u001B[38;5;66;03m# Стараемся добиться максимально релевантных, неповторяющихся рекомендаций\u001B[39;00m\n\u001B[1;32m     97\u001B[0m rec_list \u001B[38;5;241m=\u001B[39m []\n",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     92\u001B[0m recs_for_items \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m top_items[:N]:\n\u001B[0;32m---> 94\u001B[0m     recs_for_items\u001B[38;5;241m.\u001B[39mappend([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mid_to_itemid[\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilar_items\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitemid_to_id\u001B[49m\u001B[43m[\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m[i][\u001B[38;5;241m0\u001B[39m]] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, N \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)])\n\u001B[1;32m     96\u001B[0m \u001B[38;5;66;03m# Стараемся добиться максимально релевантных, неповторяющихся рекомендаций\u001B[39;00m\n\u001B[1;32m     97\u001B[0m rec_list \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Projects/GeekBrainsAI/RecSys/venv/lib/python3.8/site-packages/implicit/cpu/matrix_factorization_base.py:175\u001B[0m, in \u001B[0;36mMatrixFactorizationBase.similar_items\u001B[0;34m(self, itemid, N, recalculate_item, item_users, filter_items, items)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msimilar_items\u001B[39m(\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m, itemid, N\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, recalculate_item\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, item_users\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, filter_items\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, items\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    174\u001B[0m ):\n\u001B[0;32m--> 175\u001B[0m     factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_item_factor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitemid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem_users\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecalculate_item\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m     factors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitem_factors\n\u001B[1;32m    177\u001B[0m     norms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitem_norms\n",
      "File \u001B[0;32m~/Projects/GeekBrainsAI/RecSys/venv/lib/python3.8/site-packages/implicit/cpu/matrix_factorization_base.py:135\u001B[0m, in \u001B[0;36mMatrixFactorizationBase._item_factor\u001B[0;34m(self, itemid, item_users, recalculate_item)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recalculate_item:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecalculate_item(itemid, item_users)\n\u001B[0;32m--> 135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem_factors\u001B[49m\u001B[43m[\u001B[49m\u001B[43mitemid\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: index 4194 is out of bounds for axis 0 with size 2479"
     ]
    }
   ],
   "source": [
    "recomender = MainRecommender(data_train)\n",
    "\n",
    "popularity = data_train.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
    "popularity.sort_values('quantity', ascending=False, inplace=True)\n",
    "\n",
    "popularity = popularity[popularity['item_id'] != 999999]\n",
    "popularity = popularity.groupby('user_id').head(5)\n",
    "popularity.sort_values(by=['user_id','quantity'], ascending=False, inplace=True)\n",
    "\n",
    "popularity['similar_recommendation_bpr'] = popularity['user_id'].apply(lambda x: recomender.get_similar_items_recommendation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: similar_recommendation_bpr'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m precision_at_k\n\u001B[0;32m----> 2\u001B[0m recommendation_similar_items \u001B[38;5;241m=\u001B[39m \u001B[43mpopularity\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muser_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msimilar_recommendation_bpr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mfirst()\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m      3\u001B[0m recommendation_similar_items\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilar_recommendation_bpr\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      5\u001B[0m result_predict \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mmerge(recommendation_similar_items, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_id\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Projects/GeekBrainsAI/RecSys/venv/lib/python3.8/site-packages/pandas/core/groupby/generic.py:1338\u001B[0m, in \u001B[0;36mDataFrameGroupBy.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(key) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1330\u001B[0m     \u001B[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001B[39;00m\n\u001B[1;32m   1331\u001B[0m     \u001B[38;5;66;03m# valid syntax, so don't raise warning\u001B[39;00m\n\u001B[1;32m   1332\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1333\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIndexing with multiple keys (implicitly converted to a tuple \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1334\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof keys) will be deprecated, use a list instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1335\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m   1336\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m   1337\u001B[0m     )\n\u001B[0;32m-> 1338\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/GeekBrainsAI/RecSys/venv/lib/python3.8/site-packages/pandas/core/base.py:250\u001B[0m, in \u001B[0;36mSelectionMixin.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj:\n\u001B[0;32m--> 250\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn not found: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    251\u001B[0m     subset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj[key]\n\u001B[1;32m    252\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m subset\u001B[38;5;241m.\u001B[39mndim\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Column not found: similar_recommendation_bpr'"
     ]
    }
   ],
   "source": [
    "from metrics import precision_at_k\n",
    "recommendation_similar_items = popularity.groupby('user_id')['similar_recommendation_bpr'].first().reset_index()\n",
    "recommendation_similar_items.columns=['user_id', 'similar_recommendation_bpr']\n",
    "\n",
    "result_predict = result.merge(recommendation_similar_items, on='user_id', how='inner')\n",
    "result_predict.apply(lambda row: precision_at_k(row['similar_recommendation_bpr'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}